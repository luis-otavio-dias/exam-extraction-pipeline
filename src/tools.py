import asyncio
import json
from pathlib import Path

import fitz
from langchain.tools import BaseTool, tool
from langchain_text_splitters.character import RecursiveCharacterTextSplitter
from pypdf import PdfReader

from prompts import STRUCTURE_QUESTION_PROMPT
from utils import load_google_generative_ai_model

exam_pdf_path = Path(__file__).parent.parent / "pdfs" / "prova.pdf"
answer_key_pdf_path = Path(__file__).parent.parent / "pdfs" / "gabarito.pdf"


def _pdf_extract_text_impl(
    pdf_path: Path,
    start_page: int | None = None,
    end_page: int | None = None,
) -> str:
    """
    Extract and returns text from a PDF file between start_page and end_page.
    Returns the extracted text as a string containing the text of each page
    separated by line breaks and identified by the page number.
    Args:
        pdf_path (Path): Path to the PDF file.
        start_page (int): Initial page (inclusive).
        end_page (int): End page (exclusive).
    Returns:
        str: Extracted text from the PDF.
    """
    text = ""

    with fitz.open(pdf_path) as pdf:
        total_pages = pdf.page_count

        start: int = 0 if start_page is None or start_page < 0 else start_page

        end: int = (
            total_pages
            if end_page is None or end_page > total_pages
            else end_page
        )

        if start >= end:
            return ""

        for page_num in range(start, end):
            page = pdf[page_num]
            page_text = page.get_text()
            text += f"\n\n --- Page {page_num + 1} --- \n\n{page_text}"

    return text


@tool
def pdf_extract_jpegs(
    pdf_path: Path,
    output_dir: Path = Path("output_images"),
    start_page: int | None = None,
    end_page: int | None = None,
) -> str:
    """
    Extracts JPEG images from a PDF file and saves them to a specified
    directory.

    Args:
        pdf_path (Path): Path to the PDF file.
        output_dir (Path): Path to the output directory.
        start_page (int): Initial page (inclusive).
        end_page (int): End page (exclusive).

    Returns:
        str: Message indicating the number of images extracted and the output
        directory.
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    with pdf_path.open("rb") as pdf:
        reader = PdfReader(pdf)
        total_pages = len(reader.pages)

        start: int = 0 if start_page is None or start_page < 0 else start_page

        end: int = (
            total_pages
            if end_page is None or end_page > total_pages
            else end_page
        )

        saved = 0
        for page_index in range(start, end):
            page = reader.pages[page_index]
            for image_file_object in page.images:
                if image_file_object.name.find(".png") == -1:
                    img_name = f"page_{page_index+1}_{image_file_object.name}"

                    out_path = output_dir / img_name
                    with out_path.open("wb") as fp:
                        fp.write(image_file_object.data)
                    saved += 1

    if saved == 0:
        return "No JPEG images found in the specified page range."
    return f"{saved} JPEG images saved in '{output_dir.resolve()}'"


@tool
def extract_exam_pdf_text(
    exam_pdf_path: Path,
    answer_key_pdf_path: Path,
    exam_start_page: int | None = None,
    exam_end_page: int | None = None,
) -> str:
    """
    Extracts text from an exam PDF and an answer key PDF, saving it to a
    temporary .txt file. Returns the path to this temporary file. The
    resulting file path should be used as input for structure_questions.

    Args:
        exam_pdf_path (Path): Path to the exam PDF file.
        answer_key_pdf_path (Path): Path to the answer key PDF file.
        start_page (int): Initial page (inclusive).
        end_page (int): End page (exclusive).

    Returns:
        str: Path to the temporary .txt file containing the extracted text.
    """

    exam_text = _pdf_extract_text_impl(
        exam_pdf_path, start_page=exam_start_page, end_page=exam_end_page
    )

    if answer_key_pdf_path.exists():
        answer_key_text = _pdf_extract_text_impl(pdf_path=answer_key_pdf_path)
        exam_text += "\n\n--- Answer Key ---\n\n" + answer_key_text

    temp_dir = Path("temp")
    temp_dir.mkdir(exist_ok=True)
    temp_file = temp_dir / "extracted_text.txt"

    with temp_file.open("w", encoding="utf-8") as f:
        f.write(exam_text)

    return str(temp_file)


@tool
async def structure_questions(extracted_text_path: str) -> str:
    """
    Receive a string that is the path to the .txt file generated by the
    extract_exam_pdf_text tool. Use the content of this file for extracting
    the questions in JSON format.
    This tool MUST NOT be used with any other text.

    Args:
        extracted_text_path (str): Path to the .txt file generated by the
        extract_exam_pdf_text tool.
    Returns:
        str: JSON array with the structured questions.
    """
    extracted_text = await asyncio.to_thread(
        Path(extracted_text_path).read_text, encoding="utf-8"
    )

    parts = extracted_text.split("\n\n--- Answer Key ---\n\n", 1)
    exam_text = parts[0]
    answer_key_text = parts[1] if parts[1] else "No answer key found."

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=20000,
        chunk_overlap=500,
    )

    text_chunks = text_splitter.split_text(exam_text)

    all_results = []

    llm = load_google_generative_ai_model(
        model_name="gemini-2.5-flash-lite", temperature=0
    )

    for chunk in text_chunks:

        prompt = STRUCTURE_QUESTION_PROMPT.format(
            chunk=chunk, answer_key_text=answer_key_text
        )

        chunked_response = await llm.ainvoke(prompt)
        all_results.extend(chunked_response.content)

        await asyncio.sleep(1)

    return json.dumps(all_results, indent=2, ensure_ascii=False)


TOOLS: list[BaseTool] = [
    pdf_extract_jpegs,
    extract_exam_pdf_text,
    structure_questions,
]
TOOLS_BY_NAME: dict[str, BaseTool] = {tool.name: tool for tool in TOOLS}
