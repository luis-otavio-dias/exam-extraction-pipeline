import asyncio
import json
from pathlib import Path

from langchain.tools import BaseTool, tool
from langchain_text_splitters.character import RecursiveCharacterTextSplitter
from pypdf import PdfReader

from utils import load_google_generative_ai_model

exam_pdf_path = Path(__file__).parent.parent / "pdfs" / "prova.pdf"
answer_key_pdf_path = Path(__file__).parent.parent / "pdfs" / "gabarito.pdf"


def _pdf_extract_text_impl(
    pdf_path: Path,
    start_page: int | None = None,
    end_page: int | None = None,
) -> str:
    """
    Extract and returns text from a PDF file between start_page and end_page.
    Returns the extracted text as a string containing the text of each page
    separated by line breaks and identified by the page number.
    Args:
        pdf_path (Path): Path to the PDF file.
        start_page (int): Initial page (inclusive).
        end_page (int): End page (exclusive).
    Returns:
        str: Extracted text from the PDF.
    """
    text = ""
    pages_text = {}

    with pdf_path.open("rb") as pdf:
        reader = PdfReader(pdf)
        total_pages = len(reader.pages)

        if start_page is None or start_page < 0:
            start_page = 0
        if end_page is None or end_page > total_pages:
            end_page = total_pages
        if start_page >= end_page:
            return ""

        for page in reader.pages[start_page:end_page]:
            page_no = reader.pages.index(page) + 1
            page_text = page.extract_text()
            pages_text[page_no] = page_text
            text += f"\n\n --- Page {page_no} --- \n\n{page_text}"

    return text


@tool
def pdf_extract_jpegs(
    pdf_path: Path,
    output_dir: Path = Path("media_images"),
    start_page: int | None = None,
    end_page: int | None = None,
) -> str:
    """
    Extracts JPEG images from a PDF file and saves them to a specified
    directory.

    Args:
        pdf_path (Path): Path to the PDF file.
        output_dir (Path): Path to the output directory.
        start_page (int): Initial page (inclusive).
        end_page (int): End page (exclusive).

    Returns:
        str: Message indicating the number of images extracted and the output
        directory.
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    with pdf_path.open("rb") as pdf:
        reader = PdfReader(pdf)
        total_pages = len(reader.pages)

        if start_page is None or start_page < 0:
            start_page = 0
        if end_page is None or end_page > total_pages:
            end_page = total_pages
        if start_page >= end_page:
            return "Intervalo de páginas inválido."

        saved = 0
        for page_index in range(start_page, end_page):
            page = reader.pages[page_index]
            for image_file_object in page.images:
                if image_file_object.name.find(".jpg") != -1:
                    img_name = f"page_{page_index+1}_{image_file_object.name}"

                    out_path = output_dir / img_name
                    with out_path.open("wb") as fp:
                        fp.write(image_file_object.data)
                    saved += 1

    if saved == 0:
        return "No JPEG images found in the specified page range."
    return f"{saved} JPEG images saved in '{output_dir.resolve()}'"


@tool
def extract_exam_pdf_text(
    exam_pdf_path: Path,
    answer_key_pdf_path: Path,
    exam_start_page: int | None = None,
    exam_end_page: int | None = None,
) -> str:
    """
    Extracts text from an exam PDF and an answer key PDF, saving it to a
    temporary .txt file. Returns the path to this temporary file. The
    resulting file path should be used as input for structure_questions.

    Args:
        exam_pdf_path (Path): Path to the exam PDF file.
        answer_key_pdf_path (Path): Path to the answer key PDF file.
        start_page (int): Initial page (inclusive).
        end_page (int): End page (exclusive).

    Returns:
        str: Path to the temporary .txt file containing the extracted text.
    """

    exam_text = _pdf_extract_text_impl(
        exam_pdf_path, start_page=exam_start_page, end_page=exam_end_page
    )

    if answer_key_pdf_path.exists():
        answer_key_text = _pdf_extract_text_impl(pdf_path=answer_key_pdf_path)
        exam_text += "\n\n--- Gabarito ---\n\n" + answer_key_text

    temp_dir = Path("temp")
    temp_dir.mkdir(exist_ok=True)
    temp_file = temp_dir / "extracted_text.txt"

    with temp_file.open("w", encoding="utf-8") as f:
        f.write(exam_text)

    return str(temp_file)


@tool
async def structure_questions(extracted_text_path: str) -> str:
    """
    Receive a string that is the path to the .txt file generated by the
    extract_exam_pdf_text tool. Use the content of this file for extracting
    the questions in JSON format.
    This tool MUST NOT be used with any other text.

    Args:
        extracted_text_path (str): Path to the .txt file generated by the
        extract_exam_pdf_text tool.
    Returns:
        str: JSON array with the structured questions.
    """
    extracted_text = await asyncio.to_thread(
        Path(extracted_text_path).read_text, encoding="utf-8"
    )

    parts = extracted_text.split("\n\n--- Gabarito ---\n\n", 1)
    exam_text = parts[0]
    answer_key_text = parts[1] if parts[1] else "No answer key found."

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=20000,
        chunk_overlap=500,
    )

    text_chunks = text_splitter.split_text(exam_text)

    all_results = []

    llm = load_google_generative_ai_model(
        model_name="gemini-2.5-flash-lite", temperature=0
    )

    for chunk in text_chunks:

        prompt = f"""
    You are an expert data extractor. Your task is to extract exam questions from the text below and match them with the provided Answer Key.
    
    Rules:
    1. Output MUST be a valid JSON Array. One object per question.
    2. Use the provided Answer Key to fill the 'correct_option' field.
    3. If a question is split or incomplete at the start/end of the text and cannot be fully understood, IGNORE IT.
    4. Image extraction: If the question implies an image, set "image": true.
    
    Target JSON Structure:
    {{
        "question": "Question number (e.g., '01', '10')",
        "image": boolean,
        "passage_text": "Text of the associated passage/text/poem. Include source if present in passage but put citation in 'sources'. Empty string if none.",
        "sources": ["List of source strings (URLs, Books, access dates)"],
        "statement": "The question statement itself",
        "options": {{ "A": "...", "B": "...", "C": "...", "D": "...", "E": "..."}},
        "correct_option": "Letter only (A, B, C, D, or E)"
    }}


    Exam Text Fragment:
    {chunk}

    Answer Key:
    {answer_key_text}
    """

        chunked_response = await llm.ainvoke(prompt)
        all_results.extend(chunked_response.content)

        await asyncio.sleep(1)

    return json.dumps(all_results, indent=2, ensure_ascii=False)


TOOLS: list[BaseTool] = [
    pdf_extract_jpegs,
    extract_exam_pdf_text,
    structure_questions,
]
TOOLS_BY_NAME: dict[str, BaseTool] = {tool.name: tool for tool in TOOLS}
